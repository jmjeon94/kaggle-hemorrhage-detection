{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset path\n",
    "DATA_DF_PATH = './dataset/'\n",
    "DATA_IMG_PATH = '../dataset/kaggle_rsna(only100)/'\n",
    "\n",
    "# hyper parameter\n",
    "MODEL_NAME = 'DenseNet121'\n",
    "LOSS_NAME = 'BCE'\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "INITIAL_LR = 0.001\n",
    "\n",
    "# etc path\n",
    "MODEL_WEIGHTS_SAVE_PATH = './checkpoints/'\n",
    "MODEL_WEIGHTS_LOAD_PATH = './checkpoints/'\n",
    "TENSORBOARD_PATH = './tensorboard/'\n",
    "\n",
    "# gpu settings\n",
    "IS_GPU_PARALLEL = True if torch.cuda.device_count()>1 else False\n",
    "\n",
    "# train id\n",
    "timestamp = datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "TRAIN_ID = f'{timestamp}_{MODEL_NAME}_LR{INITIAL_LR}_BS{BATCH_SIZE}_{LOSS_NAME}Loss'\n",
    "\n",
    "# dataset mode\n",
    "DATASET_MODE = 'sequential' # '3ch' or 'sequential'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121_change_avg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121_change_avg, self).__init__()\n",
    "        self.densenet121 = torchvision.models.densenet121(pretrained=True).features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.mlp = nn.Linear(1024, 6)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.densenet121(x)      \n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x_features = x.view(-1, 1024)\n",
    "        x = self.mlp(x_features)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x, x_features\n",
    "    \n",
    "model = DenseNet121_change_avg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "model = DenseNet121_change_avg()\n",
    "# summary(model, (3,512,512), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform 전처리기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "transforms = T.Compose([T.Resize([256,256]),\n",
    "                        T.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HmDataset(Dataset):\n",
    "    def __init__(self, df_path, transforms=None, mode='3ch'):\n",
    "        self.df = pd.read_csv(df_path)\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        hm_meta = self.df.iloc[index]\n",
    "        filename = hm_meta.filename\n",
    "        label = torch.from_numpy(hm_meta['epidural':'any'].values.astype(np.float))\n",
    "        \n",
    "        img = Image.open('../dataset/kaggle_rsna(only100)/imgs/'+filename+'.png')\n",
    "        \n",
    "        if self.mode=='sequential':\n",
    "            study_instance_uid = hm_meta.study_instance_uid\n",
    "            slice_id_current = hm_meta.slice_id\n",
    "            \n",
    "            # 해당 환자의 DataFrame\n",
    "            tmp_df = self.df[self.df.study_instance_uid==study_instance_uid]\n",
    "            \n",
    "            # 해당 환자의 slice 전체 수 \n",
    "            max_slice = tmp_df.shape[0]\n",
    "            \n",
    "            # get prev, next slice number\n",
    "            slice_id_prev = slice_id_current if slice_id_current==0 else slice_id_current-1\n",
    "            slice_id_next = slice_id_current if slice_id_current==max_slice-1 else slice_id_current+1\n",
    "            \n",
    "            # get prev, next filename\n",
    "            filename_prev = tmp_df[tmp_df.slice_id==slice_id_prev].iloc[0].filename\n",
    "            filename_next = tmp_df[tmp_df.slice_id==slice_id_next].iloc[0].filename\n",
    "            \n",
    "            # get prev, next img\n",
    "            img_prev = Image.open('../dataset/kaggle_rsna(only100)/imgs/'+filename_prev+'.png')\n",
    "            img_next = Image.open('../dataset/kaggle_rsna(only100)/imgs/'+filename_next+'.png')\n",
    "            \n",
    "            # concat 3 imgs\n",
    "            img = np.concatenate([np.expand_dims(np.array(img)[:,:,0], axis=2),\n",
    "                                   np.expand_dims(np.array(img_prev)[:,:,0], axis=2),\n",
    "                                   np.expand_dims(np.array(img_next)[:,:,0], axis=2)],\n",
    "                                  axis=2)\n",
    "            img = Image.fromarray(img)\n",
    "                                   \n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        \n",
    "        return filename, label, img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "train_dataset = HmDataset(df_path='./dataset/train.csv', transforms=transforms, mode=DATASET_MODE)\n",
    "valid_dataset = HmDataset(df_path='./dataset/valid.csv', transforms=transforms, mode=DATASET_MODE)\n",
    "test_dataset = HmDataset(df_path='./dataset/test.csv', transforms=transforms, mode=DATASET_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  DenseNet121_change_avg()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(phase, epoch, model, data_loader, optimizer, criterion, device):\n",
    "    \n",
    "    losses = 0\n",
    "    if phase=='Train':\n",
    "        model.train()\n",
    "    elif phase=='Valid' or phase=='Test':\n",
    "        model.eval()\n",
    "    \n",
    "    tbar = tqdm(data_loader, position=0, leave=True)\n",
    "    for data in tbar:\n",
    "        \n",
    "        _, target, input_img = data\n",
    "        target, input_img = target.to(device), input_img.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predicted_label, _ = model(input_img)\n",
    "        loss = criterion(predicted_label, target.float())\n",
    "        \n",
    "        if phase=='Train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "#         predicted_label_thresholded = predicted_label>0.5\n",
    "#         acc = (predicted_label_thresholded==target).sum() # \n",
    "\n",
    "        losses += loss.item()\n",
    "        \n",
    "        tbar.set_description(f'[{phase}]\\tEpoch:[{epoch}/{EPOCHS}]\\tLoss:{losses/len(data_loader):.5f}')# '\\tAcc:{acc:.2%}')\n",
    "        \n",
    "    return losses/len(data_loader)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]\tEpoch:[1/10]\tLoss:0.16818: 100%|██████████| 44/44 [01:12<00:00,  1.66s/it]\n",
      "[Valid]\tEpoch:[1/10]\tLoss:0.22321: 100%|██████████| 6/6 [00:04<00:00,  1.40it/s]\n",
      "[Train]\tEpoch:[2/10]\tLoss:0.15044: 100%|██████████| 44/44 [01:11<00:00,  1.62s/it]\n",
      "[Valid]\tEpoch:[2/10]\tLoss:0.21755: 100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n",
      "[Train]\tEpoch:[3/10]\tLoss:0.13760: 100%|██████████| 44/44 [01:10<00:00,  1.61s/it]\n",
      "[Valid]\tEpoch:[3/10]\tLoss:0.21481: 100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n",
      "[Train]\tEpoch:[4/10]\tLoss:0.12487: 100%|██████████| 44/44 [01:10<00:00,  1.61s/it]\n",
      "[Valid]\tEpoch:[4/10]\tLoss:0.22203: 100%|██████████| 6/6 [00:04<00:00,  1.45it/s]\n",
      "[Train]\tEpoch:[5/10]\tLoss:0.11269: 100%|██████████| 44/44 [01:10<00:00,  1.60s/it]\n",
      "[Valid]\tEpoch:[5/10]\tLoss:0.21631: 100%|██████████| 6/6 [00:04<00:00,  1.44it/s]\n",
      "[Train]\tEpoch:[6/10]\tLoss:0.10314: 100%|██████████| 44/44 [01:10<00:00,  1.61s/it]\n",
      "[Valid]\tEpoch:[6/10]\tLoss:0.21955: 100%|██████████| 6/6 [00:04<00:00,  1.34it/s]\n",
      "[Train]\tEpoch:[7/10]\tLoss:0.09627: 100%|██████████| 44/44 [01:12<00:00,  1.65s/it]\n",
      "[Valid]\tEpoch:[7/10]\tLoss:0.22544: 100%|██████████| 6/6 [00:04<00:00,  1.41it/s]\n",
      "[Train]\tEpoch:[8/10]\tLoss:0.08859: 100%|██████████| 44/44 [01:12<00:00,  1.65s/it]\n",
      "[Valid]\tEpoch:[8/10]\tLoss:0.22232: 100%|██████████| 6/6 [00:04<00:00,  1.39it/s]\n",
      "[Train]\tEpoch:[9/10]\tLoss:0.08159: 100%|██████████| 44/44 [01:12<00:00,  1.65s/it]\n",
      "[Valid]\tEpoch:[9/10]\tLoss:0.22949: 100%|██████████| 6/6 [00:04<00:00,  1.41it/s]\n",
      "[Train]\tEpoch:[10/10]\tLoss:0.07979: 100%|██████████| 44/44 [01:12<00:00,  1.66s/it]\n",
      "[Valid]\tEpoch:[10/10]\tLoss:0.22186: 100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# tensorboard log\n",
    "writer = SummaryWriter(log_dir=os.path.join(TENSORBOARD_PATH, TRAIN_ID))\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "        \n",
    "    # fit\n",
    "    train_loss = fit('Train', epoch, model, train_loader, optimizer, criterion, device)\n",
    "    with torch.no_grad():\n",
    "        valid_loss = fit('Valid', epoch, model, valid_loader, optimizer, criterion, device)\n",
    "        \n",
    "    # log\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    # tensor board\n",
    "    writer.add_scalar('Loss/Train/', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Valid/', valid_loss, epoch)\n",
    "#     writer.add_scalar('Accuracy/Train/', accuracy, epoch+1)\n",
    "\n",
    "    # save model\n",
    "    save_checkpoint(epoch, model, optimizer)\n",
    "\n",
    "# 학습 완료 시, 메일 전송\n",
    "send_mail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, model, optimizer, scheduler=None):\n",
    "    \n",
    "    save_folder_dir = os.path.join(MODEL_WEIGHTS_SAVE_PATH, TRAIN_ID)\n",
    "    if not os.path.exists(save_folder_dir):\n",
    "        os.makedirs(save_folder_dir, exist_ok=True)\n",
    "    model_save_path = os.path.join(save_folder_dir, f'{epoch:3d}.pth')\n",
    "    \n",
    "    if IS_GPU_PARALLEL:\n",
    "        model_state_dict = model.module.state_dict()\n",
    "    else:\n",
    "        model_state_dict = model.state_dict()\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler = scheduler.state_dict()\n",
    "        \n",
    "    torch.save({\n",
    "        'epoch':epoch,\n",
    "        'model_state_dict':model_state_dict,\n",
    "        'optimizer':optimizer.state_dict(),\n",
    "        'scheduler':scheduler\n",
    "    }, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(ckpt_path, model, optimizer=None, scheduler=None):\n",
    "    \n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise ValueError('No ckpt in [{}]'.format(ckpt_path))\n",
    "        \n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    epoch = ckpt['epoch']\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        optimizer.load_state_dict(ckpt['optimizer'])\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.load_state_dict(ckpt['scheduler'])\n",
    "    \n",
    "    return model, optimizer, scheduler, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "def send_mail():\n",
    "    # 세션생성, 로그인\n",
    "    s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    s.starttls()  # TLS 사용시 필요\n",
    "    s.login('jmjeon3155@gmail.com', 'simyiexludrwsxwn')\n",
    "\n",
    "    # 제목, 본문 작성\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = '[알림]학습완료'\n",
    "    msg.attach(MIMEText('AWS EC2 종료할것!', 'plain'))\n",
    "\n",
    "    # 메일 전송\n",
    "    s.sendmail(\"jmjeon3155@gmail.com\", \"jmjeon3155@gmail.com\", msg.as_string())\n",
    "    s.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
