{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121_change_avg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121_change_avg, self).__init__()\n",
    "        self.densenet121 = torchvision.models.densenet121(pretrained=True).features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.mlp = nn.Linear(1024, 6)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.densenet121(x)      \n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x_features = x.view(-1, 1024)\n",
    "        x = self.mlp(x_features)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x, x_features\n",
    "    \n",
    "model = DenseNet121_change_avg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "model = DenseNet121_change_avg()\n",
    "# summary(model, (3,512,512), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform 전처리기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "transforms = T.Compose([T.Resize([256,256]),\n",
    "                        T.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class HmDataset(Dataset):\n",
    "    def __init__(self, df_path, transforms=None):\n",
    "        self.df = pd.read_csv(df_path)\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        hm_meta = self.df.iloc[index]\n",
    "        filename = hm_meta.filename\n",
    "        label = torch.from_numpy(hm_meta['epidural':'any'].values.astype(np.float))\n",
    "        \n",
    "        img = Image.open('../dataset/kaggle_rsna(only100)/imgs/'+filename+'.png')\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        \n",
    "        return filename, label, img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "train_dataset = HmDataset(df_path='./train.csv', transforms=transforms)\n",
    "valid_dataset = HmDataset(df_path='./valid.csv', transforms=transforms)\n",
    "test_dataset = HmDataset(df_path='./valid.csv', transforms=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Hyper Parameter\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  DenseNet121_change_avg()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.cuda()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(phase, epoch, model, data_loader, optimizer, criterion, device):\n",
    "    \n",
    "    losses = []\n",
    "    if phase=='Train':\n",
    "        model.train()\n",
    "    elif phase=='Valid' or phase=='Test':\n",
    "        model.eval()\n",
    "    \n",
    "    tbar = tqdm(data_loader, position=0, leave=True)\n",
    "    for data in tbar:\n",
    "        \n",
    "        _, target, input_img = data\n",
    "        target, input_img = target.to(device), input_img.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predicted_label, predicted_features = model(input_img)\n",
    "        loss = criterion(predicted_label, target.float())\n",
    "        \n",
    "        if phase=='Train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "#         predicted_label_thresholded = predicted_label>0.5\n",
    "#         acc = (predicted_label_thresholded==target).sum() # \n",
    "\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        tbar.set_description(f'[{phase}]\\tEpoch:[{epoch+1}/{EPOCHS}]\\tLoss:{loss:.5f}')# '\\tAcc:{acc:.2%}')\n",
    "        \n",
    "    return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]\tEpoch:[1/10]\tLoss:0.22127: 100%|██████████| 44/44 [01:11<00:00,  1.63s/it]\n",
      "[Valid]\tEpoch:[1/10]\tLoss:0.06066: 100%|██████████| 44/44 [00:25<00:00,  1.73it/s]\n",
      "[Train]\tEpoch:[2/10]\tLoss:0.16601:  45%|████▌     | 20/44 [00:33<00:38,  1.62s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = fit('Train', epoch, model, train_loader, optimizer, criterion, device)\n",
    "    with torch.no_grad():\n",
    "        valid_loss = fit('Valid', epoch, model, valid_loader, optimizer, criterion, device)\n",
    "        \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_losses)\n",
    "print(valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
